---
layout: post
title:  "Torch: å›¾åƒåˆ†ç±»ï¼ŒGAN,DCGAN"
date:   2020-02-25 13:34:47 +0800
categories: jekyll update
---


#  Kaggleä¸Šçš„ç‹—å“ç§è¯†åˆ«ï¼ˆImageNet Dogsï¼‰

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è§£å†³Kaggleç«èµ›ä¸­çš„çŠ¬ç§è¯†åˆ«æŒ‘æˆ˜ï¼Œæ¯”èµ›çš„ç½‘å€æ˜¯https://www.kaggle.com/c/dog-breed-identification åœ¨è¿™é¡¹æ¯”èµ›ä¸­ï¼Œæˆ‘ä»¬å°è¯•ç¡®å®š120ç§ä¸åŒçš„ç‹—ã€‚è¯¥æ¯”èµ›ä¸­ä½¿ç”¨çš„æ•°æ®é›†å®é™…ä¸Šæ˜¯è‘—åçš„ImageNetæ•°æ®é›†çš„å­é›†ã€‚


```python
# åœ¨æœ¬èŠ‚notebookä¸­ï¼Œä½¿ç”¨åç»­è®¾ç½®çš„å‚æ•°åœ¨å®Œæ•´è®­ç»ƒé›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œå¤§è‡´éœ€è¦40-50åˆ†é’Ÿ
# è¯·å¤§å®¶åˆç†å®‰æ’GPUæ—¶é•¿ï¼Œå°½é‡åªåœ¨è®­ç»ƒæ—¶åˆ‡æ¢åˆ°GPUèµ„æº
# ä¹Ÿå¯ä»¥åœ¨Kaggleä¸Šè®¿é—®æœ¬èŠ‚notebookï¼š
# https://www.kaggle.com/boyuai/boyu-d2l-dog-breed-identification-imagenet-dogs
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
import os
import shutil
import time
import pandas as pd
import random
```


```python
# è®¾ç½®éšæœºæ•°ç§å­
random.seed(0)
torch.manual_seed(0)
torch.cuda.manual_seed(0)
```

## æ•´ç†æ•°æ®é›†

æˆ‘ä»¬å¯ä»¥ä»æ¯”èµ›ç½‘å€ä¸Šä¸‹è½½æ•°æ®é›†ï¼Œå…¶ç›®å½•ç»“æ„ä¸ºï¼š

```
| Dog Breed Identification
    | train
    |   | 000bec180eb18c7604dcecc8fe0dba07.jpg
    |   | 00a338a92e4e7bf543340dc849230e75.jpg
    |   | ...
    | test
    |   | 00a3edd22dc7859c487a64777fc8d093.jpg
    |   | 00a6892e5c7f92c1f465e213fd904582.jpg
    |   | ...
    | labels.csv
    | sample_submission.csv
```

trainå’Œtestç›®å½•ä¸‹åˆ†åˆ«æ˜¯è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å›¾åƒï¼Œè®­ç»ƒé›†åŒ…å«10,222å¼ å›¾åƒï¼Œæµ‹è¯•é›†åŒ…å«10,357å¼ å›¾åƒï¼Œå›¾åƒæ ¼å¼éƒ½æ˜¯JPEGï¼Œæ¯å¼ å›¾åƒçš„æ–‡ä»¶åæ˜¯ä¸€ä¸ªå”¯ä¸€çš„idã€‚labels.csvåŒ…å«è®­ç»ƒé›†å›¾åƒçš„æ ‡ç­¾ï¼Œæ–‡ä»¶åŒ…å«10,222è¡Œï¼Œæ¯è¡ŒåŒ…å«ä¸¤åˆ—ï¼Œç¬¬ä¸€åˆ—æ˜¯å›¾åƒidï¼Œç¬¬äºŒåˆ—æ˜¯ç‹—çš„ç±»åˆ«ã€‚ç‹—çš„ç±»åˆ«ä¸€å…±æœ‰120ç§ã€‚

æˆ‘ä»¬å¸Œæœ›å¯¹æ•°æ®è¿›è¡Œæ•´ç†ï¼Œæ–¹ä¾¿åç»­çš„è¯»å–ï¼Œæˆ‘ä»¬çš„ä¸»è¦ç›®æ ‡æ˜¯ï¼š

* ä»è®­ç»ƒé›†ä¸­åˆ’åˆ†å‡ºéªŒè¯æ•°æ®é›†ï¼Œç”¨äºè°ƒæ•´è¶…å‚æ•°ã€‚åˆ’åˆ†ä¹‹åï¼Œæ•°æ®é›†åº”è¯¥åŒ…å«4ä¸ªéƒ¨åˆ†ï¼šåˆ’åˆ†åçš„è®­ç»ƒé›†ã€åˆ’åˆ†åçš„éªŒè¯é›†ã€å®Œæ•´è®­ç»ƒé›†ã€å®Œæ•´æµ‹è¯•é›†
* å¯¹äº4ä¸ªéƒ¨åˆ†ï¼Œå»ºç«‹4ä¸ªæ–‡ä»¶å¤¹ï¼štrain, valid, train_valid, testã€‚åœ¨ä¸Šè¿°æ–‡ä»¶å¤¹ä¸­ï¼Œå¯¹æ¯ä¸ªç±»åˆ«éƒ½å»ºç«‹ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œåœ¨å…¶ä¸­å­˜æ”¾å±äºè¯¥ç±»åˆ«çš„å›¾åƒã€‚å‰ä¸‰ä¸ªéƒ¨åˆ†çš„æ ‡ç­¾å·²çŸ¥ï¼Œæ‰€ä»¥å„æœ‰120ä¸ªå­æ–‡ä»¶å¤¹ï¼Œè€Œæµ‹è¯•é›†çš„æ ‡ç­¾æœªçŸ¥ï¼Œæ‰€ä»¥ä»…å»ºç«‹ä¸€ä¸ªåä¸ºunknownçš„å­æ–‡ä»¶å¤¹ï¼Œå­˜æ”¾æ‰€æœ‰æµ‹è¯•æ•°æ®ã€‚

æˆ‘ä»¬å¸Œæœ›æ•´ç†åçš„æ•°æ®é›†ç›®å½•ç»“æ„ä¸ºï¼š
```
| train_valid_test
    | train
    |   | affenpinscher
    |   |   | 00ca18751837cd6a22813f8e221f7819.jpg
    |   |   | ...
    |   | afghan_hound
    |   |   | 0a4f1e17d720cdff35814651402b7cf4.jpg
    |   |   | ...
    |   | ...
    | valid
    |   | affenpinscher
    |   |   | 56af8255b46eb1fa5722f37729525405.jpg
    |   |   | ...
    |   | afghan_hound
    |   |   | 0df400016a7e7ab4abff824bf2743f02.jpg
    |   |   | ...
    |   | ...
    | train_valid
    |   | affenpinscher
    |   |   | 00ca18751837cd6a22813f8e221f7819.jpg
    |   |   | ...
    |   | afghan_hound
    |   |   | 0a4f1e17d720cdff35814651402b7cf4.jpg
    |   |   | ...
    |   | ...
    | test
    |   | unknown
    |   |   | 00a3edd22dc7859c487a64777fc8d093.jpg
    |   |   | ...
```


```python
data_dir = '/home/kesci/input/Kaggle_Dog6357/dog-breed-identification'  # æ•°æ®é›†ç›®å½•
label_file, train_dir, test_dir = 'labels.csv', 'train', 'test'  # data_dirä¸­çš„æ–‡ä»¶å¤¹ã€æ–‡ä»¶
new_data_dir = './train_valid_test'  # æ•´ç†ä¹‹åçš„æ•°æ®å­˜æ”¾çš„ç›®å½•
valid_ratio = 0.1  # éªŒè¯é›†æ‰€å æ¯”ä¾‹
```


```python
def mkdir_if_not_exist(path):
    # è‹¥ç›®å½•pathä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºç›®å½•
    if not os.path.exists(os.path.join(*path)):
        os.makedirs(os.path.join(*path))
        
def reorg_dog_data(data_dir, label_file, train_dir, test_dir, new_data_dir, valid_ratio):
    # è¯»å–è®­ç»ƒæ•°æ®æ ‡ç­¾
    labels = pd.read_csv(os.path.join(data_dir, label_file))
    id2label = {Id: label for Id, label in labels.values}  # (key: value): (id: label)

    # éšæœºæ‰“ä¹±è®­ç»ƒæ•°æ®
    train_files = os.listdir(os.path.join(data_dir, train_dir))
    random.shuffle(train_files)    

    # åŸè®­ç»ƒé›†
    valid_ds_size = int(len(train_files) * valid_ratio)  # éªŒè¯é›†å¤§å°
    for i, file in enumerate(train_files):
        img_id = file.split('.')[0]  # fileæ˜¯å½¢å¼ä¸ºid.jpgçš„å­—ç¬¦ä¸²
        img_label = id2label[img_id]
        if i < valid_ds_size:
            mkdir_if_not_exist([new_data_dir, 'valid', img_label])
            shutil.copy(os.path.join(data_dir, train_dir, file),
                        os.path.join(new_data_dir, 'valid', img_label))
        else:
            mkdir_if_not_exist([new_data_dir, 'train', img_label])
            shutil.copy(os.path.join(data_dir, train_dir, file),
                        os.path.join(new_data_dir, 'train', img_label))
        mkdir_if_not_exist([new_data_dir, 'train_valid', img_label])
        shutil.copy(os.path.join(data_dir, train_dir, file),
                    os.path.join(new_data_dir, 'train_valid', img_label))

    # æµ‹è¯•é›†
    mkdir_if_not_exist([new_data_dir, 'test', 'unknown'])
    for test_file in os.listdir(os.path.join(data_dir, test_dir)):
        shutil.copy(os.path.join(data_dir, test_dir, test_file),
                    os.path.join(new_data_dir, 'test', 'unknown'))
```


```python
reorg_dog_data(data_dir, label_file, train_dir, test_dir, new_data_dir, valid_ratio)
```

## å›¾åƒå¢å¼º


```python
transform_train = transforms.Compose([
    # éšæœºå¯¹å›¾åƒè£å‰ªå‡ºé¢ç§¯ä¸ºåŸå›¾åƒé¢ç§¯0.08~1å€ã€ä¸”é«˜å’Œå®½ä¹‹æ¯”åœ¨3/4~4/3çš„å›¾åƒï¼Œå†æ”¾ç¼©ä¸ºé«˜å’Œå®½å‡ä¸º224åƒç´ çš„æ–°å›¾åƒ
    transforms.RandomResizedCrop(224, scale=(0.08, 1.0),  
                                 ratio=(3.0/4.0, 4.0/3.0)),
    # ä»¥0.5çš„æ¦‚ç‡éšæœºæ°´å¹³ç¿»è½¬
    transforms.RandomHorizontalFlip(),
    # éšæœºæ›´æ”¹äº®åº¦ã€å¯¹æ¯”åº¦å’Œé¥±å’Œåº¦
    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),
    transforms.ToTensor(),
    # å¯¹å„ä¸ªé€šé“åšæ ‡å‡†åŒ–ï¼Œ(0.485, 0.456, 0.406)å’Œ(0.229, 0.224, 0.225)æ˜¯åœ¨ImageNetä¸Šè®¡ç®—å¾—çš„å„é€šé“å‡å€¼ä¸æ–¹å·®
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNetä¸Šçš„å‡å€¼å’Œæ–¹å·®
])

# åœ¨æµ‹è¯•é›†ä¸Šçš„å›¾åƒå¢å¼ºåªåšç¡®å®šæ€§çš„æ“ä½œ
transform_test = transforms.Compose([
    transforms.Resize(256),
    # å°†å›¾åƒä¸­å¤®çš„é«˜å’Œå®½å‡ä¸º224çš„æ­£æ–¹å½¢åŒºåŸŸè£å‰ªå‡ºæ¥
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
```

## è¯»å–æ•°æ®


```python
# new_data_dirç›®å½•ä¸‹æœ‰train, valid, train_valid, testå››ä¸ªç›®å½•
# è¿™å››ä¸ªç›®å½•ä¸­ï¼Œæ¯ä¸ªå­ç›®å½•è¡¨ç¤ºä¸€ç§ç±»åˆ«ï¼Œç›®å½•ä¸­æ˜¯å±äºè¯¥ç±»åˆ«çš„æ‰€æœ‰å›¾åƒ
train_ds = torchvision.datasets.ImageFolder(root=os.path.join(new_data_dir, 'train'),
                                            transform=transform_train)
valid_ds = torchvision.datasets.ImageFolder(root=os.path.join(new_data_dir, 'valid'),
                                            transform=transform_test)
train_valid_ds = torchvision.datasets.ImageFolder(root=os.path.join(new_data_dir, 'train_valid'),
                                            transform=transform_train)
test_ds = torchvision.datasets.ImageFolder(root=os.path.join(new_data_dir, 'test'),
                                            transform=transform_test)
```


```python
batch_size = 128
train_iter = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)
valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size=batch_size, shuffle=True)
train_valid_iter = torch.utils.data.DataLoader(train_valid_ds, batch_size=batch_size, shuffle=True)
test_iter = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)  # shuffle=False
```

## å®šä¹‰æ¨¡å‹

è¿™ä¸ªæ¯”èµ›çš„æ•°æ®å±äºImageNetæ•°æ®é›†çš„å­é›†ï¼Œæˆ‘ä»¬ä½¿ç”¨å¾®è°ƒçš„æ–¹æ³•ï¼Œé€‰ç”¨åœ¨ImageNetå®Œæ•´æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹æ¥æŠ½å–å›¾åƒç‰¹å¾ï¼Œä»¥ä½œä¸ºè‡ªå®šä¹‰å°è§„æ¨¡è¾“å‡ºç½‘ç»œçš„è¾“å…¥ã€‚

æ­¤å¤„æˆ‘ä»¬ä½¿ç”¨ä¸è®­ç»ƒçš„ResNet-34æ¨¡å‹ï¼Œç›´æ¥å¤ç”¨é¢„è®­ç»ƒæ¨¡å‹åœ¨è¾“å‡ºå±‚çš„è¾“å…¥ï¼Œå³æŠ½å–çš„ç‰¹å¾ï¼Œç„¶åæˆ‘ä»¬é‡æ–°å®šä¹‰è¾“å‡ºå±‚ï¼Œæœ¬æ¬¡æˆ‘ä»¬ä»…å¯¹é‡å®šä¹‰çš„è¾“å‡ºå±‚çš„å‚æ•°è¿›è¡Œè®­ç»ƒï¼Œè€Œå¯¹äºç”¨äºæŠ½å–ç‰¹å¾çš„éƒ¨åˆ†ï¼Œæˆ‘ä»¬ä¿ç•™é¢„è®­ç»ƒæ¨¡å‹çš„å‚æ•°ã€‚


```python
def get_net(device):
    finetune_net = models.resnet34(pretrained=False)  # é¢„è®­ç»ƒçš„resnet34ç½‘ç»œ
    finetune_net.load_state_dict(torch.load('/home/kesci/input/resnet347742/resnet34-333f7ec4.pth'))
    for param in finetune_net.parameters():  # å†»ç»“å‚æ•°
        param.requires_grad = False
    # åŸfinetune_net.fcæ˜¯ä¸€ä¸ªè¾“å…¥å•å…ƒæ•°ä¸º512ï¼Œè¾“å‡ºå•å…ƒæ•°ä¸º1000çš„å…¨è¿æ¥å±‚
    # æ›¿æ¢æ‰åŸfinetune_net.fcï¼Œæ–°finetuen_net.fcä¸­çš„æ¨¡å‹å‚æ•°ä¼šè®°å½•æ¢¯åº¦
    finetune_net.fc = nn.Sequential(
        nn.Linear(in_features=512, out_features=256),
        nn.ReLU(),
        nn.Linear(in_features=256, out_features=120)  # 120æ˜¯è¾“å‡ºç±»åˆ«æ•°
    )
    return finetune_net
```

## å®šä¹‰è®­ç»ƒå‡½æ•°


```python
def evaluate_loss_acc(data_iter, net, device):
    # è®¡ç®—data_iterä¸Šçš„å¹³å‡æŸå¤±ä¸å‡†ç¡®ç‡
    loss = nn.CrossEntropyLoss()
    is_training = net.training  # Bool netæ˜¯å¦å¤„äºtrainæ¨¡å¼
    net.eval()
    l_sum, acc_sum, n = 0, 0, 0
    with torch.no_grad():
        for X, y in data_iter:
            X, y = X.to(device), y.to(device)
            y_hat = net(X)
            l = loss(y_hat, y)
            l_sum += l.item() * y.shape[0]
            acc_sum += (y_hat.argmax(dim=1) == y).sum().item()
            n += y.shape[0]
    net.train(is_training)  # æ¢å¤netçš„train/evalçŠ¶æ€
    return l_sum / n, acc_sum / n
```


```python
def train(net, train_iter, valid_iter, num_epochs, lr, wd, device, lr_period,
          lr_decay):
    loss = nn.CrossEntropyLoss()
    optimizer = optim.SGD(net.fc.parameters(), lr=lr, momentum=0.9, weight_decay=wd)
    net = net.to(device)
    for epoch in range(num_epochs):
        train_l_sum, n, start = 0.0, 0, time.time()
        if epoch > 0 and epoch % lr_period == 0:  # æ¯lr_periodä¸ªepochï¼Œå­¦ä¹ ç‡è¡°å‡ä¸€æ¬¡
            lr = lr * lr_decay
            for param_group in optimizer.param_groups:
                param_group['lr'] = lr
        for X, y in train_iter:
            X, y = X.to(device), y.to(device)
            optimizer.zero_grad()
            y_hat = net(X)
            l = loss(y_hat, y)
            l.backward()
            optimizer.step()
            train_l_sum += l.item() * y.shape[0]
            n += y.shape[0]
        time_s = "time %.2f sec" % (time.time() - start)
        if valid_iter is not None:
            valid_loss, valid_acc = evaluate_loss_acc(valid_iter, net, device)
            epoch_s = ("epoch %d, train loss %f, valid loss %f, valid acc %f, "
                       % (epoch + 1, train_l_sum / n, valid_loss, valid_acc))
        else:
            epoch_s = ("epoch %d, train loss %f, "
                       % (epoch + 1, train_l_sum / n))
        print(epoch_s + time_s + ', lr ' + str(lr))
```

## è°ƒå‚


```python
num_epochs, lr_period, lr_decay = 20, 10, 0.1
lr, wd = 0.03, 1e-4
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```


```python
net = get_net(device)
train(net, train_iter, valid_iter, num_epochs, lr, wd, device, lr_period, lr_decay)
```

## åœ¨å®Œæ•´æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹


```python
# ä½¿ç”¨ä¸Šé¢çš„å‚æ•°è®¾ç½®ï¼Œåœ¨å®Œæ•´æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹å¤§è‡´éœ€è¦40-50åˆ†é’Ÿçš„æ—¶é—´
net = get_net(device)
train(net, train_valid_iter, None, num_epochs, lr, wd, device, lr_period, lr_decay)
```

## å¯¹æµ‹è¯•é›†åˆ†ç±»å¹¶æäº¤ç»“æœ

ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œé¢„æµ‹ã€‚æ¯”èµ›è¦æ±‚å¯¹æµ‹è¯•é›†ä¸­çš„æ¯å¼ å›¾ç‰‡ï¼Œéƒ½è¦é¢„æµ‹å…¶å±äºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡ã€‚


```python
preds = []
for X, _ in test_iter:
    X = X.to(device)
    output = net(X)
    output = torch.softmax(output, dim=1)
    preds += output.tolist()
ids = sorted(os.listdir(os.path.join(new_data_dir, 'test/unknown')))
with open('submission.csv', 'w') as f:
    f.write('id,' + ','.join(train_valid_ds.classes) + '\n')
    for i, output in zip(ids, preds):
        f.write(i.split('.')[0] + ',' + ','.join(
            [str(num) for num in output]) + '\n')
```

# Generative Adversarial Networks


Throughout most of this book, we have talked about how to make predictions. In some form or another, we used deep neural networks learned mappings from data points to labels. This kind of learning is called discriminative learning, as in, we'd like to be able to discriminate between photos cats and photos of dogs. Classifiers and regressors are both examples of discriminative learning. And neural networks trained by backpropagation have upended everything we thought we knew about discriminative learning on large complicated datasets. Classification accuracies on high-res images has gone from useless to human-level (with some caveats) in just 5-6 years. We will spare you another spiel about all the other discriminative tasks where deep neural networks do astoundingly well.

But there is more to machine learning than just solving discriminative tasks. For example, given a large dataset, without any labels, we might want to learn a model that concisely captures the characteristics of this data. Given such a model, we could sample synthetic data points that resemble the distribution of the training data. For example, given a large corpus of photographs of faces, we might want to be able to generate a new photorealistic image that looks like it might plausibly have come from the same dataset. This kind of learning is called generative modeling.

Until recently, we had no method that could synthesize novel photorealistic images. But the success of deep neural networks for discriminative learning opened up new possibilities. One big trend over the last three years has been the application of discriminative deep nets to overcome challenges in problems that we do not generally think of as supervised learning problems. The recurrent neural network language models are one example of using a discriminative network (trained to predict the next character) that once trained can act as a generative model.

In 2014, a breakthrough paper introduced Generative adversarial networks (GANs) `Goodfellow.Pouget-Abadie.Mirza.ea.2014`, a clever new way to leverage the power of discriminative models to get good generative models. At their heart, GANs rely on the idea that a data generator is good if we cannot tell fake data apart from real data. In statistics, this is called a two-sample test - a test to answer the question whether datasets $X=\{x_1,\ldots, x_n\}$ and $X'=\{x'_1,\ldots, x'_n\}$ were drawn from the same distribution. The main difference between most statistics papers and GANs is that the latter use this idea in a constructive way. In other words, rather than just training a model to say "hey, these two datasets do not look like they came from the same distribution", they use the [two-sample test](https://en.wikipedia.org/wiki/Two-sample_hypothesis_testing) to provide training signals to a generative model. This allows us to improve the data generator until it generates something that resembles the real data. At the very least, it needs to fool the classifier. Even if our classifier is a state of the art deep neural network.


![Image Name](https://cdn.kesci.com/upload/image/q5tv0m8ro4.jpg?imageView2/0/w/320/h/320)


The GAN architecture is illustrated.As you can see, there are two pieces in GAN architecture - first off, we need a device (say, a deep network but it really could be anything, such as a game rendering engine) that might potentially be able to generate data that looks just like the real thing. If we are dealing with images, this needs to generate images. If we are dealing with speech, it needs to generate audio sequences, and so on. We call this the generator network. The second component is the discriminator network. It attempts to distinguish fake and real data from each other. Both networks are in competition with each other. The generator network attempts to fool the discriminator network. At that point, the discriminator network adapts to the new fake data. This information, in turn is used to improve the generator network, and so on.


The discriminator is a binary classifier to distinguish if the input $x$ is real (from real data) or fake (from the generator). Typically, the discriminator outputs a scalar prediction $o\in\mathbb R$ for input $\mathbf x$, such as using a dense layer with hidden size 1, and then applies sigmoid function to obtain the predicted probability $D(\mathbf x) = 1/(1+e^{-o})$. Assume the label $y$ for the true data is $1$ and $0$ for the fake data. We train the discriminator to minimize the cross-entropy loss, *i.e.*,


$$
 \min_D \{ - y \log D(\mathbf x) - (1-y)\log(1-D(\mathbf x)) \},
$$


For the generator, it first draws some parameter $\mathbf z\in\mathbb R^d$ from a source of randomness, *e.g.*, a normal distribution $\mathbf z \sim \mathcal{N} (0, 1)$. We often call $\mathbf z$ as the latent variable. It then applies a function to generate $\mathbf x'=G(\mathbf z)$. The goal of the generator is to fool the discriminator to classify $\mathbf x'=G(\mathbf z)$ as true data, *i.e.*, we want $D( G(\mathbf z)) \approx 1$. In other words, for a given discriminator $D$, we update the parameters of the generator $G$ to maximize the cross-entropy loss when $y=0$, *i.e.*,


$$
 \max_G \{ - (1-y) \log(1-D(G(\mathbf z))) \} = \max_G \{ - \log(1-D(G(\mathbf z))) \}.
$$


If the discriminator does a perfect job, then $D(\mathbf x')\approx 0$ so the above loss near 0, which results the gradients are too small to make a good progress for the generator. So commonly we minimize the following loss:


$$
 \min_G \{ - y \log(D(G(\mathbf z))) \} = \min_G \{ - \log(D(G(\mathbf z))) \}, 
$$


which is just feed $\mathbf x'=G(\mathbf z)$ into the discriminator but giving label $y=1$.


To sum up, $D$ and $G$ are playing a "minimax" game with the comprehensive objective function:


$$
min_D max_G \{ -E_{x \sim \text{Data}} log D(\mathbf x) - E_{z \sim \text{Noise}} log(1 - D(G(\mathbf z))) \}.
$$




Many of the GANs applications are in the context of images. As a demonstration purpose, we are going to content ourselves with fitting a much simpler distribution first. We will illustrate what happens if we use GANs to build the world's most inefficient estimator of parameters for a Gaussian. Let's get started.


```python
%matplotlib inline
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from torch import nn
import numpy as np
from torch.autograd import Variable
import torch
```

## Generate some "real" data

Since this is going to be the world's lamest example, we simply generate data drawn from a Gaussian.


```python
X=np.random.normal(size=(1000,2))
A=np.array([[1,2],[-0.1,0.5]])
b=np.array([1,2])
data=X.dot(A)+b
```

Let's see what we got. This should be a Gaussian shifted in some rather arbitrary way with mean $b$ and covariance matrix $A^TA$.


```python
plt.figure(figsize=(3.5,2.5))
plt.scatter(X[:100,0],X[:100,1],color='red')
plt.show()
plt.figure(figsize=(3.5,2.5))
plt.scatter(data[:100,0],data[:100,1],color='blue')
plt.show()
print("The covariance matrix is\n%s" % np.dot(A.T, A))
```


<img src="https://cdn.kesci.com/rt_upload/D794A0FAF6C74E17AF54E8636B5A7B11/q5tv542z95.png">



<img src="https://cdn.kesci.com/rt_upload/D794A0FAF6C74E17AF54E8636B5A7B11/q5tv55ag0i.png">


    The covariance matrix is
    [[1.01 1.95]
     [1.95 4.25]]



```python
batch_size=8
data_iter=DataLoader(data,batch_size=batch_size)
```

## Generator

Our generator network will be the simplest network possible - a single layer linear model. This is since we will be driving that linear network with a Gaussian data generator. Hence, it literally only needs to learn the parameters to fake things perfectly.


```python
class net_G(nn.Module):
    def __init__(self):
        super(net_G,self).__init__()
        self.model=nn.Sequential(
            nn.Linear(2,2),
        )
        self._initialize_weights()
    def forward(self,x):
        x=self.model(x)
        return x
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m,nn.Linear):
                m.weight.data.normal_(0,0.02)
                m.bias.data.zero_()
```

## Discriminator

For the discriminator we will be a bit more discriminating: we will use an MLP with 3 layers to make things a bit more interesting.


```python
class net_D(nn.Module):
    def __init__(self):
        super(net_D,self).__init__()
        self.model=nn.Sequential(
            nn.Linear(2,5),
            nn.Tanh(),
            nn.Linear(5,3),
            nn.Tanh(),
            nn.Linear(3,1),
            nn.Sigmoid()
        )
        self._initialize_weights()
    def forward(self,x):
        x=self.model(x)
        return x
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m,nn.Linear):
                m.weight.data.normal_(0,0.02)
                m.bias.data.zero_()
```

## Training

First we define a function to update the discriminator.


```python
# Saved in the d2l package for later use
def update_D(X,Z,net_D,net_G,loss,trainer_D):
    batch_size=X.shape[0]
    Tensor=torch.FloatTensor
    ones=Variable(Tensor(np.ones(batch_size))).view(batch_size,1)
    zeros = Variable(Tensor(np.zeros(batch_size))).view(batch_size,1)
    real_Y=net_D(X.float())
    fake_X=net_G(Z)
    fake_Y=net_D(fake_X)
    loss_D=(loss(real_Y,ones)+loss(fake_Y,zeros))/2
    loss_D.backward()
    trainer_D.step()
    return float(loss_D.sum())
```

The generator is updated similarly. Here we reuse the cross-entropy loss but change the label of the fake data from $0$ to $1$.


```python
# Saved in the d2l package for later use
def update_G(Z,net_D,net_G,loss,trainer_G):
    batch_size=Z.shape[0]
    Tensor=torch.FloatTensor
    ones=Variable(Tensor(np.ones((batch_size,)))).view(batch_size,1)
    fake_X=net_G(Z)
    fake_Y=net_D(fake_X)
    loss_G=loss(fake_Y,ones)
    loss_G.backward()
    trainer_G.step()
    return float(loss_G.sum())
```

Both the discriminator and the generator performs a binary logistic regression with the cross-entropy loss. We use Adam to smooth the training process. In each iteration, we first update the discriminator and then the generator. We visualize both losses and generated examples.


```python
def train(net_D,net_G,data_iter,num_epochs,lr_D,lr_G,latent_dim,data):
    loss=nn.BCELoss()
    Tensor=torch.FloatTensor
    trainer_D=torch.optim.Adam(net_D.parameters(),lr=lr_D)
    trainer_G=torch.optim.Adam(net_G.parameters(),lr=lr_G)
    plt.figure(figsize=(7,4))
    d_loss_point=[]
    g_loss_point=[]
    d_loss=0
    g_loss=0
    for epoch in range(1,num_epochs+1):
        d_loss_sum=0
        g_loss_sum=0
        batch=0
        for X in data_iter:
            batch+=1
            X=Variable(X)
            batch_size=X.shape[0]
            Z=Variable(Tensor(np.random.normal(0,1,(batch_size,latent_dim))))
            trainer_D.zero_grad()
            d_loss = update_D(X, Z, net_D, net_G, loss, trainer_D)
            d_loss_sum+=d_loss
            trainer_G.zero_grad()
            g_loss = update_G(Z, net_D, net_G, loss, trainer_G)
            g_loss_sum+=g_loss
        d_loss_point.append(d_loss_sum/batch)
        g_loss_point.append(g_loss_sum/batch)
    plt.ylabel('Loss', fontdict={'size': 14})
    plt.xlabel('epoch', fontdict={'size': 14})
    plt.xticks(range(0,num_epochs+1,3))
    plt.plot(range(1,num_epochs+1),d_loss_point,color='orange',label='discriminator')
    plt.plot(range(1,num_epochs+1),g_loss_point,color='blue',label='generator')
    plt.legend()
    plt.show()
    print(d_loss,g_loss)
    
    Z =Variable(Tensor( np.random.normal(0, 1, size=(100, latent_dim))))
    fake_X=net_G(Z).detach().numpy()
    plt.figure(figsize=(3.5,2.5))
    plt.scatter(data[:,0],data[:,1],color='blue',label='real')
    plt.scatter(fake_X[:,0],fake_X[:,1],color='orange',label='generated')
    plt.legend()
    plt.show()
```

Now we specify the hyper-parameters to fit the Gaussian distribution.


```python
if __name__ == '__main__':
    lr_D,lr_G,latent_dim,num_epochs=0.05,0.005,2,20
    generator=net_G()
    discriminator=net_D()
    train(discriminator,generator,data_iter,num_epochs,lr_D,lr_G,latent_dim,data)
```


<img src="https://cdn.kesci.com/rt_upload/B915456475D04449812F7DC0E4D0DA76/q5tv6qn49u.png">


    0.6932446360588074 0.6927103996276855



<img src="https://cdn.kesci.com/rt_upload/B915456475D04449812F7DC0E4D0DA76/q5tv6qvb4s.png">


## Summary

* Generative adversarial networks (GANs) composes of two deep networks, the generator and the discriminator.
* The generator generates the image as much closer to the true image as possible to fool the discriminator, via maximizing the cross-entropy loss, *i.e.*, $\max \log(D(\mathbf{x'}))$.
* The discriminator tries to distinguish the generated images from the true images, via minimizing the cross-entropy loss, *i.e.*, $\min - y \log D(\mathbf{x}) - (1-y)\log(1-D(\mathbf{x}))$.

## Exercises

* Does an equilibrium exist where the generator wins, *i.e.* the discriminator ends up unable to distinguish the two distributions on finite samples?


# Deep Convolutional Generative Adversarial Networks

we introduced the basic ideas behind how GANs work. We showed that they can draw samples from some simple, easy-to-sample distribution, like a uniform or normal distribution, and transform them into samples that appear to match the distribution of some dataset. And while our example of matching a 2D Gaussian distribution got the point across, it is not especially exciting.

In this section, we will demonstrate how you can use GANs to generate photorealistic images. We will be basing our models on the deep convolutional GANs (DCGAN) introduced in :cite:`Radford.Metz.Chintala.2015`. We will borrow the convolutional architecture that have proven so successful for discriminative computer vision problems and show how via GANs, they can be leveraged to generate photorealistic images.


```python
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from torch import nn
import numpy as np
from torch.autograd import Variable
import torch
from torchvision.datasets import ImageFolder
from torchvision.transforms import transforms
import zipfile
cuda = True if torch.cuda.is_available() else False
print(cuda)
```

    True


## The Pokemon Dataset

The dataset we will use is a collection of Pokemon sprites obtained from [pokemondb](https://pokemondb.net/sprites). First download, extract and load this dataset.

We resize each image into $64\times 64$. The `ToTensor` transformation will project the pixel value into $[0, 1]$, while our generator will use the tanh function to obtain outputs in $[-1, 1]$. Therefore we normalize the data with $0.5$ mean and $0.5$ standard deviation to match the value range.


```python
import os
```


```python
os.system('tar -jcf pkm.tar.bz2 /home/kesci/input/pokemon8600 ')
```




    0




```python
os.system('du -sh  /home/kesci/input/CIFAR102891/cifar-10/*')
```




    0




```python
os.system('tar -jcf cifar-10_test.tar.bz2 /home/kesci/input/CIFAR102891/cifar-10/test ')
os.system('tar -jcf cifar-10_train.tar.bz2 /home/kesci/input/CIFAR102891/cifar-10/train ')
os.system('tar -jcf cifar-10_train_valid.tar.bz2 /home/kesci/input/CIFAR102891/cifar-10/train_valid')
os.system('tar -jcf cifar-10_valid.tar.bz2 /home/kesci/input/CIFAR102891/cifar-10/valid ')
```




    0




```python
os.system('cp cifar-10_test.tar.bz2 cifar-10_test2.tar.bz2')
```




    0




```python
os.system('split -b 200m cifar-10_test.tar.bz2')
```




    0




```python
ls -tlh
```

    total 1.3G
    -rw-r--r-- 1 kesci users  45M Feb 24 15:21 xad
    -rw-r--r-- 1 kesci users 200M Feb 24 15:21 xac
    -rw-r--r-- 1 kesci users 200M Feb 24 15:21 xab
    -rw-r--r-- 1 kesci users 200M Feb 24 15:21 xaa
    -rw-r--r-- 1 kesci users 645M Feb 24 14:50 cifar-10_test.tar.bz2
    -rw-r--r-- 1 kesci users  17K Feb 24 12:44 d2len9900.tar.bz2
    -rw-r--r-- 1 kesci users 5.6M Feb 19 08:46 fra.tar.gz
    -rw-r--r-- 1 kesci users  17K Feb 19 08:40 d2l.tar.gz
    drwxr-xr-x 3 kesci users 4.0K Feb 19 08:39 [0m[01;34md2l[0m/
    drwx------ 2 root  root   16K Feb 19 08:34 [01;34mlost+found[0m/



```python

```


```python
data_dir='/home/kesci/input/pokemon8600/'
batch_size=256
transform=transforms.Compose([
    transforms.Resize((64,64)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))
])
pokemon=ImageFolder(data_dir+'pokemon',transform)
data_iter=DataLoader(pokemon,batch_size=batch_size,shuffle=True)
```

Let's visualize the first 20 images.


```python
fig=plt.figure(figsize=(4,4))
imgs=data_iter.dataset.imgs
for i in range(20):
    img = plt.imread(imgs[i*150][0])
    plt.subplot(4,5,i+1)
    plt.imshow(img)
    plt.axis('off')
plt.show()
```


<img src="https://cdn.kesci.com/rt_upload/0106E502D1D840CF8557FCDFFB22742A/q5uaekg30e.png">


## The Generator

The generator needs to map the noise variable $\mathbf z\in\mathbb R^d$, a length-$d$ vector, to a RGB image with width and height to be $64\times 64$ . In :numref:`sec_fcn` we introduced the fully convolutional network that uses transposed convolution layer (refer to :numref:`sec_transposed_conv`) to enlarge input size. The basic block of the generator contains a transposed convolution layer followed by the batch normalization and ReLU activation.


```python
class G_block(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=4,strides=2, padding=1):
        super(G_block,self).__init__()
        self.conv2d_trans=nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size,
                                             stride=strides, padding=padding, bias=False)
        self.batch_norm=nn.BatchNorm2d(out_channels,0.8)
        self.activation=nn.ReLU()
    def forward(self,x):
        return self.activation(self.batch_norm(self.conv2d_trans(x)))
```

In default, the transposed convolution layer uses a $k_h = k_w = 4$ kernel, a $s_h = s_w = 2$ strides, and a $p_h = p_w = 1$ padding. With a input shape of $n_h^{'} \times n_w^{'} = 16 \times 16$, the generator block will double input's width and height.


$$
\begin{aligned}
n_h^{'} \times n_w^{'} &= [(n_h k_h - (n_h-1)(k_h-s_h)- 2p_h] \times [(n_w k_w - (n_w-1)(k_w-s_w)- 2p_w]\\
  &= [(k_h + s_h (n_h-1)- 2p_h] \times [(k_w + s_w (n_w-1)- 2p_w]\\
  &= [(4 + 2 \times (16-1)- 2 \times 1] \times [(4 + 2 \times (16-1)- 2 \times 1]\\
  &= 32 \times 32 .\\
\end{aligned}
$$



```python
Tensor=torch.cuda.FloatTensor
x=Variable(Tensor(np.zeros((2,3,16,16))))
g_blk=G_block(3,20)
g_blk.cuda()
print(g_blk(x).shape)
```

    torch.Size([2, 20, 32, 32])


If changing the transposed convolution layer to a $4\times 4$ kernel, $1\times 1$ strides and zero padding. With a input size of $1 \times 1$, the output will have its width and height increased by 3 respectively.


```python
x=Variable(Tensor(np.zeros((2,3,1,1))))
g_blk=G_block(3,20,strides=1,padding=0)
g_blk.cuda()
print(g_blk(x).shape)
```

    torch.Size([2, 20, 4, 4])


The generator consists of four basic blocks that increase input's both width and height from 1 to 32. At the same time, it first projects the latent variable into $64\times 8$ channels, and then halve the channels each time. At last, a transposed convolution layer is used to generate the output. It further doubles the width and height to match the desired $64\times 64$ shape, and reduces the channel size to $3$. The tanh activation function is applied to project output values into the $(-1, 1)$ range.


```python
class net_G(nn.Module):
    def __init__(self,in_channels):
        super(net_G,self).__init__()

        n_G=64
        self.model=nn.Sequential(
            G_block(in_channels,n_G*8,strides=1,padding=0),
            G_block(n_G*8,n_G*4),
            G_block(n_G*4,n_G*2),
            G_block(n_G*2,n_G),
            nn.ConvTranspose2d(
                n_G,3,kernel_size=4,stride=2,padding=1,bias=False
            ),
            nn.Tanh()
        )
    def forward(self,x):
        x=self.model(x)
        return x


def weights_init_normal(m):
    classname = m.__class__.__name__
    if classname.find("Conv") != -1:
        torch.nn.init.normal_(m.weight.data, mean=0, std=0.02)
    elif classname.find("BatchNorm2d") != -1:
        torch.nn.init.normal_(m.weight.data, mean=1.0, std=0.02)
        torch.nn.init.constant_(m.bias.data, 0.0)
```

Generate a 100 dimensional latent variable to verify the generator's output shape.


```python
x=Variable(Tensor(np.zeros((1,100,1,1))))
generator=net_G(100)
generator.cuda()
generator.apply(weights_init_normal)
print(generator(x).shape)
```

    torch.Size([1, 3, 64, 64])


## Discriminator

The discriminator is a normal convolutional network network except that it uses a leaky ReLU as its activation function. Given $\alpha \in[0, 1]$, its definition is


$$
\textrm{leaky ReLU}(x) = \begin{cases}x & \text{if}\ x > 0\\ \alpha x &\text{otherwise}\end{cases}.
$$


As it can be seen, it is normal ReLU if $\alpha=0$, and an identity function if $\alpha=1$. For $\alpha \in (0, 1)$, leaky ReLU is a nonlinear function that give a non-zero output for a negative input. It aims to fix the "dying ReLU" problem that a neuron might always output a negative value and therefore cannot make any progress since the gradient of ReLU is 0.


```python
alphas = [0, 0.2, 0.4, .6]
x = np.arange(-2, 1, 0.1)
Y = [nn.LeakyReLU(alpha)(Tensor(x)).cpu().numpy()for alpha in alphas]
plt.figure(figsize=(4,4))
for y in Y:
    plt.plot(x,y)
plt.show()
```


<img src="https://cdn.kesci.com/rt_upload/9AA265C8E2D54CB7851745C8BB41C84B/q5uaek48k0.png">


The basic block of the discriminator is a convolution layer followed by a batch normalization layer and a leaky ReLU activation. The hyper-parameters of the convolution layer are similar to the transpose convolution layer in the generator block.


```python
class D_block(nn.Module):
    def __init__(self,in_channels,out_channels,kernel_size=4,strides=2,
                 padding=1,alpha=0.2):
        super(D_block,self).__init__()
        self.conv2d=nn.Conv2d(in_channels,out_channels,kernel_size,strides,padding,bias=False)
        self.batch_norm=nn.BatchNorm2d(out_channels,0.8)
        self.activation=nn.LeakyReLU(alpha)
    def forward(self,X):
        return self.activation(self.batch_norm(self.conv2d(X)))
```

A basic block with default settings will halve the width and height of the inputs, as we demonstrated in :numref:`sec_padding`. For example, given a input shape $n_h = n_w = 16 $, with a kernel shape $k_h = k_w = 4$, a stride shape $s_h = s_w = 2$, and a padding shape $p_h = p_w = 1$, the output shape will be:


$$

\begin{aligned}
n_h^{'} \times n_w^{'} &= \lfloor(n_h-k_h+2p_h+s_h)/s_h\rfloor \times \lfloor(n_w-k_w+2p_w+s_w)/s_w\rfloor\\
  &= \lfloor(16-4+2\times 1+2)/2\rfloor \times \lfloor(16-4+2\times 1+2)/2\rfloor\\
  &= 8 \times 8 .\\
\end{aligned}

$$



```python
x = Variable(Tensor(np.zeros((2, 3, 16, 16))))
d_blk = D_block(3,20)
d_blk.cuda()
print(d_blk(x).shape)
```

    torch.Size([2, 20, 8, 8])


The discriminator is a mirror of the generator.


```python
class net_D(nn.Module):
    def __init__(self,in_channels):
        super(net_D,self).__init__()
        n_D=64
        self.model=nn.Sequential(
            D_block(in_channels,n_D),
            D_block(n_D,n_D*2),
            D_block(n_D*2,n_D*4),
            D_block(n_D*4,n_D*8)
        )
        self.conv=nn.Conv2d(n_D*8,1,kernel_size=4,bias=False)
        self.activation=nn.Sigmoid()
        # self._initialize_weights()
    def forward(self,x):
        x=self.model(x)
        x=self.conv(x)
        x=self.activation(x)
        return x
```

It uses a convolution layer with output channel $1$ as the last layer to obtain a single prediction value.


```python
x = Variable(Tensor(np.zeros((1, 3, 64, 64))))
discriminator=net_D(3)
discriminator.cuda()
discriminator.apply(weights_init_normal)
print(discriminator(x).shape)
```

    torch.Size([1, 1, 1, 1])


## Training
Compared to the basic GAN in :numref:`sec_basic_gan`, we use the same learning rate for both generator and discriminator since they are similar to each other. In addition, we change $\beta_1$ in Adam (:numref:`sec_adam`) from $0.9$ to $0.5$. It decreases the smoothness of the momentum, the exponentially weighted moving average of past gradients, to take care of the rapid changing gradients because the generator and the discriminator fight with each other. Besides, the random generated noise `Z`, is a 4-D tensor and we are using GPU to accelerate the computation.


```python
def update_D(X,Z,net_D,net_G,loss,trainer_D):
    batch_size=X.shape[0]
    Tensor=torch.cuda.FloatTensor
    ones=Variable(Tensor(np.ones(batch_size,)),requires_grad=False).view(batch_size,1)
    zeros = Variable(Tensor(np.zeros(batch_size,)),requires_grad=False).view(batch_size,1)
    real_Y=net_D(X).view(batch_size,-1)
    fake_X=net_G(Z)
    fake_Y=net_D(fake_X).view(batch_size,-1)
    loss_D=(loss(real_Y,ones)+loss(fake_Y,zeros))/2
    loss_D.backward()
    trainer_D.step()
    return float(loss_D.sum())

def update_G(Z,net_D,net_G,loss,trainer_G):
    batch_size=Z.shape[0]
    Tensor=torch.cuda.FloatTensor
    ones=Variable(Tensor(np.ones((batch_size,))),requires_grad=False).view(batch_size,1)
    fake_X=net_G(Z)
    fake_Y=net_D(fake_X).view(batch_size,-1)
    loss_G=loss(fake_Y,ones)
    loss_G.backward()
    trainer_G.step()
    return float(loss_G.sum())


def train(net_D,net_G,data_iter,num_epochs,lr,latent_dim):
    loss=nn.BCELoss()
    Tensor=torch.cuda.FloatTensor
    trainer_D=torch.optim.Adam(net_D.parameters(),lr=lr,betas=(0.5,0.999))
    trainer_G=torch.optim.Adam(net_G.parameters(),lr=lr,betas=(0.5,0.999))
    plt.figure(figsize=(7,4))
    d_loss_point=[]
    g_loss_point=[]
    d_loss=0
    g_loss=0
    for epoch in range(1,num_epochs+1):
        d_loss_sum=0
        g_loss_sum=0
        batch=0
        for X in data_iter:
            X=X[:][0]
            batch+=1
            X=Variable(X.type(Tensor))
            batch_size=X.shape[0]
            Z=Variable(Tensor(np.random.normal(0,1,(batch_size,latent_dim,1,1))))

            trainer_D.zero_grad()
            d_loss = update_D(X, Z, net_D, net_G, loss, trainer_D)
            d_loss_sum+=d_loss
            trainer_G.zero_grad()
            g_loss = update_G(Z, net_D, net_G, loss, trainer_G)
            g_loss_sum+=g_loss

        d_loss_point.append(d_loss_sum/batch)
        g_loss_point.append(g_loss_sum/batch)
        print(
            "[Epoch %d/%d]  [D loss: %f] [G loss: %f]"
            % (epoch, num_epochs,  d_loss_sum/batch_size,  g_loss_sum/batch_size)
        )


    plt.ylabel('Loss', fontdict={ 'size': 14})
    plt.xlabel('epoch', fontdict={ 'size': 14})
    plt.xticks(range(0,num_epochs+1,3))
    plt.plot(range(1,num_epochs+1),d_loss_point,color='orange',label='discriminator')
    plt.plot(range(1,num_epochs+1),g_loss_point,color='blue',label='generator')
    plt.legend()
    plt.show()
    print(d_loss,g_loss)

    Z = Variable(Tensor(np.random.normal(0, 1, size=(21, latent_dim, 1, 1))),requires_grad=False)
    fake_x = generator(Z)
    fake_x=fake_x.cpu().detach().numpy()
    plt.figure(figsize=(14,6))
    for i in range(21):
        im=np.transpose(fake_x[i])
        plt.subplot(3,7,i+1)
        plt.imshow(im)
    plt.show()
```

Now let's train the model.


```python
if __name__ == '__main__':
    lr,latent_dim,num_epochs=0.005,100,50
    train(discriminator,generator,data_iter,num_epochs,lr,latent_dim)
```

## Summary

* DCGAN architecture has four convolutional layers for the Discriminator and four "fractionally-strided" convolutional layers for the Generator.
* The Discriminator is a 4-layer strided convolutions with batch normalization (except its input layer) and leaky ReLU activations. 
* Leaky ReLU is a nonlinear function that give a non-zero output for a negative input. It aims to fix the â€œdying ReLUâ€ problem and helps the gradients flow easier through the architecture.


## Exercises

* What will happen if we use standard ReLU activation rather than leaky ReLU?
* Apply DCGAN on Fashion-MNIST and see which category works well and which does not.



```python

```
