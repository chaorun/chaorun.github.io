---
layout: post
title:  "Torch CNNåŸºç¡€ä¸è¿›é˜¶&LeNet"
date:   2020-02-19 10:44:47 +0800
categories: jekyll update
---

```python
#å·ç§¯ç¥ç»ç½‘ç»œåŸºç¡€ï¼›leNetï¼›å·ç§¯ç¥ç»ç½‘ç»œè¿›é˜¶
```


```python
#ä»Šå¤©çš„å¤§éƒ¨åˆ†ç¨‹åºCPU i7-8700kéƒ½è·‘ä¸åŠ¨
#è¿˜æœ‰ä¸€å—2060çš„æœåŠ¡å™¨åœ¨å†…ç½‘ï¼Œp100éœ€è¦è·ŸåŒå­¦è¦æ—¶é—´ï¼Œå…ˆç®—äº†
```


```python
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import time
import sys
import numpy as np

sys.path.append("../Dive-into-DL-PyTorch/code/") # ä¸ºäº†å¯¼å…¥ä¸Šå±‚ç›®å½•çš„d2lzh_pytorch
import d2lzh_pytorch as d2l
sys.path.append('/Users/chaorun/')
from SoTinShuiLib import *
```


```python
def corr2d(X, K):
    H, W = X.shape
    h, w = K.shape
    Y = torch.zeros(H - h + 1, W - w + 1)
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()
    return Y
```


```python
X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])
K = torch.tensor([[0, 1], [2, 3]])
Y = corr2d(X, K)
print(Y)
```

    tensor([[19., 25.],
            [37., 43.]])



```python
class Conv2D(nn.Module):
    def __init__(self, kernel_size):
        super(Conv2D, self).__init__()
        self.weight = nn.Parameter(torch.randn(kernel_size))
        self.bias = nn.Parameter(torch.randn(1))

    def forward(self, x):
        return corr2d(x, self.weight) + self.bias
```


```python
X = torch.ones(6, 8)
Y = torch.zeros(6, 7)
X[:, 2: 6] = 0
Y[:, 1] = 1
Y[:, 5] = -1
print(X)
print(Y)
```

    tensor([[1., 1., 0., 0., 0., 0., 1., 1.],
            [1., 1., 0., 0., 0., 0., 1., 1.],
            [1., 1., 0., 0., 0., 0., 1., 1.],
            [1., 1., 0., 0., 0., 0., 1., 1.],
            [1., 1., 0., 0., 0., 0., 1., 1.],
            [1., 1., 0., 0., 0., 0., 1., 1.]])
    tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],
            [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
            [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
            [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
            [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
            [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])



```python
conv2d = Conv2D(kernel_size=(1, 2))
step = 30
lr = 0.01
for i in range(step):
    Y_hat = conv2d(X)
    l = ((Y_hat - Y) ** 2).sum()
    l.backward()
    # æ¢¯åº¦ä¸‹é™
    conv2d.weight.data -= lr * conv2d.weight.grad
    conv2d.bias.data -= lr * conv2d.bias.grad
    
    # æ¢¯åº¦æ¸…é›¶
    conv2d.weight.grad.zero_()
    conv2d.bias.grad.zero_()
    if (i + 1) % 5 == 0:
        print('Step %d, loss %.3f' % (i + 1, l.item()))
        
print(conv2d.weight.data)
print(conv2d.bias.data)
```

    Step 5, loss 27.974
    Step 10, loss 6.819
    Step 15, loss 1.791
    Step 20, loss 0.487
    Step 25, loss 0.134
    Step 30, loss 0.037
    tensor([[ 0.9525, -0.9496]])
    tensor([-0.0016])



```python
#(ğ‘›â„+ğ‘â„âˆ’ğ‘˜â„+1)Ã—(ğ‘›ğ‘¤+ğ‘ğ‘¤âˆ’ğ‘˜ğ‘¤+1)
```

#è¾“å…¥è¾“å‡ºå…³ç³»å¼å­
å¦‚æœåŸè¾“å…¥çš„é«˜å’Œå®½æ˜¯$n_{h}å’Œn_{w}$ï¼Œå·ç§¯æ ¸çš„é«˜å’Œå®½æ˜¯$k_{h}å’Œk_{w}$ï¼Œåœ¨é«˜çš„ä¸¤ä¾§ä¸€å…±å¡«å……$p_{h}$è¡Œï¼Œåœ¨å®½çš„ä¸¤ä¾§ä¸€å…±å¡«å……$p_{w}$åˆ—ï¼Œ
åˆ™è¾“å‡ºå½¢çŠ¶ä¸ºï¼š
$(n_{h}+p_{h}-k_{h}+1)\times(n_{w}+p_{w}-k_{w}+1)$

ä¸€èˆ¬æ¥è¯´ï¼Œå½“é«˜ä¸Šæ­¥å¹…ä¸º$s_{h},å®½ä¸Šæ­¥å¹…s_{w}$ æ—¶ï¼Œè¾“å‡ºå½¢çŠ¶ä¸ºï¼š
$(n_{h}+p_{h}-k_{h}+s_{h}+1)/s_{h}\times(n_{w}+p_{w}-k_{w}+s_{w}+1)/s_{w}$


```python
X = torch.rand(4, 2, 3, 5)
print(X.shape)

conv2d = nn.Conv2d(in_channels=2, out_channels=3, kernel_size=(3, 5), stride=1, padding=(1, 2))
Y = conv2d(X)
print('Y.shape: ', Y.shape)
print('weight.shape: ', conv2d.weight.shape)
print('bias.shape: ', conv2d.bias.shape)
```

    torch.Size([4, 2, 3, 5])
    Y.shape:  torch.Size([4, 3, 3, 5])
    weight.shape:  torch.Size([3, 2, 3, 5])
    bias.shape:  torch.Size([3])


# Pooling


```python
X = torch.arange(32, dtype=torch.float32).view(1, 2, 4, 4)
pool2d = nn.MaxPool2d(kernel_size=3, padding=1, stride=(2, 1))
Y = pool2d(X)
print(X)
print(Y)
```

    tensor([[[[ 0.,  1.,  2.,  3.],
              [ 4.,  5.,  6.,  7.],
              [ 8.,  9., 10., 11.],
              [12., 13., 14., 15.]],
    
             [[16., 17., 18., 19.],
              [20., 21., 22., 23.],
              [24., 25., 26., 27.],
              [28., 29., 30., 31.]]]])
    tensor([[[[ 5.,  6.,  7.,  7.],
              [13., 14., 15., 15.]],
    
             [[21., 22., 23., 23.],
              [29., 30., 31., 31.]]]])



```python
nn.AvgPool2d(kernel_size=3, padding=1, stride=(2, 1))(X)
```




    tensor([[[[ 1.1111,  2.0000,  2.6667,  2.0000],
              [ 5.6667,  9.0000, 10.0000,  7.0000]],
    
             [[ 8.2222, 12.6667, 13.3333,  9.1111],
              [16.3333, 25.0000, 26.0000, 17.6667]]]])




```python
nn.MaxPool2d(kernel_size=3, padding=1, stride=(2, 1))(X)
```




    tensor([[[[ 5.,  6.,  7.,  7.],
              [13., 14., 15., 15.]],
    
             [[21., 22., 23., 23.],
              [29., 30., 31., 31.]]]])



# LeNet æ¨¡å‹


```python
#net
class Flatten(torch.nn.Module):  #å±•å¹³æ“ä½œ
    def forward(self, x):
        return x.view(x.shape[0], -1)

class Reshape(torch.nn.Module): #å°†å›¾åƒå¤§å°é‡å®šå‹
    def forward(self, x):
        return x.view(-1,1,28,28)      #(B x C x H x W)
    
net = torch.nn.Sequential(     #Lelet                                                  
    Reshape(),
    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2), #b*1*28*28  =>b*6*28*28
    nn.Sigmoid(),                                                       
    nn.AvgPool2d(kernel_size=2, stride=2),                              #b*6*28*28  =>b*6*14*14
    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),           #b*6*14*14  =>b*16*10*10
    nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),                              #b*16*10*10  => b*16*5*5
    Flatten(),                                                          #b*16*5*5   => b*400
    nn.Linear(in_features=16*5*5, out_features=120),
    nn.Sigmoid(),
    nn.Linear(120, 84),
    nn.Sigmoid(),
    nn.Linear(84, 10)
)
```


```python
#print
X = torch.randn(size=(1,1,28,28), dtype = torch.float32)
for layer in net:
    X = layer(X)
    print(layer.__class__.__name__,'output shape: \t',X.shape)
```

    Reshape output shape: 	 torch.Size([1, 1, 28, 28])
    Conv2d output shape: 	 torch.Size([1, 6, 28, 28])
    Sigmoid output shape: 	 torch.Size([1, 6, 28, 28])
    AvgPool2d output shape: 	 torch.Size([1, 6, 14, 14])
    Conv2d output shape: 	 torch.Size([1, 16, 10, 10])
    Sigmoid output shape: 	 torch.Size([1, 16, 10, 10])
    AvgPool2d output shape: 	 torch.Size([1, 16, 5, 5])
    Flatten output shape: 	 torch.Size([1, 400])
    Linear output shape: 	 torch.Size([1, 120])
    Sigmoid output shape: 	 torch.Size([1, 120])
    Linear output shape: 	 torch.Size([1, 84])
    Sigmoid output shape: 	 torch.Size([1, 84])
    Linear output shape: 	 torch.Size([1, 10])



```python
# æ•°æ®
batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(
    batch_size=batch_size, root='/Users/chaorun/Datasets/FashionMNIST/')
print(len(train_iter))
```

    235



```python
#æ•°æ®å±•ç¤º
import matplotlib.pyplot as plt
def show_fashion_mnist(images, labels):
    d2l.use_svg_display()
    # è¿™é‡Œçš„_è¡¨ç¤ºæˆ‘ä»¬å¿½ç•¥ï¼ˆä¸ä½¿ç”¨ï¼‰çš„å˜é‡
    _, figs = plt.subplots(1, len(images), figsize=(12, 12))
    for f, img, lbl in zip(figs, images, labels):
        f.imshow(img.view((28, 28)).numpy())
        f.set_title(lbl)
        f.axes.get_xaxis().set_visible(False)
        f.axes.get_yaxis().set_visible(False)
    plt.show()

for Xdata,ylabel in train_iter:
    break
X, y = [], []
for i in range(10):
    print(Xdata[i].shape,ylabel[i].numpy())
    X.append(Xdata[i]) # å°†ç¬¬iä¸ªfeatureåŠ åˆ°Xä¸­
    y.append(ylabel[i].numpy()) # å°†ç¬¬iä¸ªlabelåŠ åˆ°yä¸­
show_fashion_mnist(X, y)
```

    torch.Size([1, 28, 28]) 6
    torch.Size([1, 28, 28]) 1
    torch.Size([1, 28, 28]) 2
    torch.Size([1, 28, 28]) 6
    torch.Size([1, 28, 28]) 8
    torch.Size([1, 28, 28]) 4
    torch.Size([1, 28, 28]) 4
    torch.Size([1, 28, 28]) 0
    torch.Size([1, 28, 28]) 3
    torch.Size([1, 28, 28]) 4



![svg](output_19_1.svg)



```python
# This function has been saved in the d2l package for future use
#use GPU
def try_gpu():
    """If GPU is available, return torch.device as cuda:0; else return torch.device as cpu."""
    if torch.cuda.is_available():
        device = torch.device('cuda:0')
    else:
        device = torch.device('cpu')
    return device

device = try_gpu()
device
```




    device(type='cpu')




```python
#è®¡ç®—å‡†ç¡®ç‡
'''
(1). net.train()
  å¯ç”¨ BatchNormalization å’Œ Dropoutï¼Œå°†BatchNormalizationå’ŒDropoutç½®ä¸ºTrue
(2). net.eval()
ä¸å¯ç”¨ BatchNormalization å’Œ Dropoutï¼Œå°†BatchNormalizationå’ŒDropoutç½®ä¸ºFalse
'''

def evaluate_accuracy(data_iter, net,device=torch.device('cpu')):
    """Evaluate accuracy of a model on the given data set."""
    acc_sum,n = torch.tensor([0],dtype=torch.float32,device=device),0
    for X,y in data_iter:
        # If device is the GPU, copy the data to the GPU.
        X,y = X.to(device),y.to(device)
        net.eval()
        with torch.no_grad():
            y = y.long()
            acc_sum += torch.sum((torch.argmax(net(X), dim=1) == y))  #[[0.2 ,0.4 ,0.5 ,0.6 ,0.8] ,[ 0.1,0.2 ,0.4 ,0.3 ,0.1]] => [ 4 , 2 ]
            n += y.shape[0]
    return acc_sum.item()/n
```


```python
#è®­ç»ƒå‡½æ•°
def train_ch5(net, train_iter, test_iter,criterion, num_epochs, batch_size, device,lr=None):
    """Train and evaluate a model with CPU or GPU."""
    print('training on', device)
    net.to(device)
    optimizer = optim.SGD(net.parameters(), lr=lr)
    for epoch in range(num_epochs):
        train_l_sum = torch.tensor([0.0],dtype=torch.float32,device=device)
        train_acc_sum = torch.tensor([0.0],dtype=torch.float32,device=device)
        n, start = 0, time.time()
        for X, y in train_iter:
            net.train()
            
            optimizer.zero_grad()
            X,y = X.to(device),y.to(device) 
            y_hat = net(X)
            loss = criterion(y_hat, y)
            loss.backward()
            optimizer.step()
            
            with torch.no_grad():
                y = y.long()
                train_l_sum += loss.float()
                train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()
                n += y.shape[0]
        test_acc = evaluate_accuracy(test_iter, net,device)
        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '
              'time %.1f sec'
              % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc,
                 time.time() - start))
```


```python
# è®­ç»ƒ
lr, num_epochs = 0.9, 10

def init_weights(m):
    if type(m) == nn.Linear or type(m) == nn.Conv2d:
        torch.nn.init.xavier_uniform_(m.weight)

net.apply(init_weights)
net = net.to(device)

criterion = nn.CrossEntropyLoss()   #äº¤å‰ç†µæè¿°äº†ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„è·ç¦»ï¼Œäº¤å‰ç†µè¶Šå°è¯´æ˜ä¸¤è€…ä¹‹é—´è¶Šæ¥è¿‘
train_ch5(net, train_iter, test_iter, criterion,num_epochs, batch_size,device, lr)
```

    training on cpu
    epoch 1, loss 0.0091, train acc 0.102, test acc 0.100, time 15.2 sec
    epoch 2, loss 0.0059, train acc 0.413, test acc 0.575, time 15.1 sec
    epoch 3, loss 0.0034, train acc 0.658, test acc 0.649, time 15.3 sec
    epoch 4, loss 0.0027, train acc 0.726, test acc 0.678, time 15.3 sec
    epoch 5, loss 0.0025, train acc 0.753, test acc 0.759, time 15.3 sec
    epoch 6, loss 0.0023, train acc 0.776, test acc 0.770, time 15.2 sec
    epoch 7, loss 0.0021, train acc 0.790, test acc 0.721, time 15.2 sec
    epoch 8, loss 0.0020, train acc 0.804, test acc 0.729, time 15.3 sec
    epoch 9, loss 0.0019, train acc 0.816, test acc 0.811, time 15.3 sec
    epoch 10, loss 0.0018, train acc 0.825, test acc 0.820, time 15.2 sec



```python
# test
for testdata,testlabe in test_iter:
    testdata,testlabe = testdata.to(device),testlabe.to(device)
    break
print(testdata.shape,testlabe.shape)
net.eval()
y_pre = net(testdata)
print(torch.argmax(y_pre,dim=1)[:10])
print(testlabe[:10])
```

    torch.Size([256, 1, 28, 28]) torch.Size([256])
    tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7])
    tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7])



```python

```

# å·ç§¯ç¥ç»ç½‘ç»œè¿›é˜¶


```python
#è€ƒè™‘åˆ°æœ¬ä»£ç ä¸­çš„æ¨¡å‹è¿‡å¤§ï¼ŒCPUè®­ç»ƒè¾ƒæ…¢ï¼Œ


import time
import torch
from torch import nn, optim
import torchvision
import numpy as np
import sys
import os
import torch.nn.functional as F

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class AlexNet(nn.Module):
    def __init__(self):
        super(AlexNet, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding
            nn.ReLU(),
            nn.MaxPool2d(3, 2), # kernel_size, stride
            # å‡å°å·ç§¯çª—å£ï¼Œä½¿ç”¨å¡«å……ä¸º2æ¥ä½¿å¾—è¾“å…¥ä¸è¾“å‡ºçš„é«˜å’Œå®½ä¸€è‡´ï¼Œä¸”å¢å¤§è¾“å‡ºé€šé“æ•°
            nn.Conv2d(96, 256, 5, 1, 2),
            nn.ReLU(),
            nn.MaxPool2d(3, 2),
            # è¿ç»­3ä¸ªå·ç§¯å±‚ï¼Œä¸”ä½¿ç”¨æ›´å°çš„å·ç§¯çª—å£ã€‚é™¤äº†æœ€åçš„å·ç§¯å±‚å¤–ï¼Œè¿›ä¸€æ­¥å¢å¤§äº†è¾“å‡ºé€šé“æ•°ã€‚
            # å‰ä¸¤ä¸ªå·ç§¯å±‚åä¸ä½¿ç”¨æ± åŒ–å±‚æ¥å‡å°è¾“å…¥çš„é«˜å’Œå®½
            nn.Conv2d(256, 384, 3, 1, 1),
            nn.ReLU(),
            nn.Conv2d(384, 384, 3, 1, 1),
            nn.ReLU(),
            nn.Conv2d(384, 256, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(3, 2)
        )
         # è¿™é‡Œå…¨è¿æ¥å±‚çš„è¾“å‡ºä¸ªæ•°æ¯”LeNetä¸­çš„å¤§æ•°å€ã€‚ä½¿ç”¨ä¸¢å¼ƒå±‚æ¥ç¼“è§£è¿‡æ‹Ÿåˆ
        self.fc = nn.Sequential(
            nn.Linear(256*5*5, 4096),
            nn.ReLU(),
            nn.Dropout(0.5),
            #ç”±äºä½¿ç”¨CPUé•œåƒï¼Œç²¾ç®€ç½‘ç»œï¼Œè‹¥ä¸ºGPUé•œåƒå¯æ·»åŠ è¯¥å±‚
            #nn.Linear(4096, 4096),
            #nn.ReLU(),
            #nn.Dropout(0.5),

            # è¾“å‡ºå±‚ã€‚ç”±äºè¿™é‡Œä½¿ç”¨Fashion-MNISTï¼Œæ‰€ä»¥ç”¨ç±»åˆ«æ•°ä¸º10ï¼Œè€Œéè®ºæ–‡ä¸­çš„1000
            nn.Linear(4096, 10),
        )

    def forward(self, img):

        feature = self.conv(img)
        output = self.fc(feature.view(img.shape[0], -1))
        return output
```


```python
net = AlexNet()
print(net)
```

    AlexNet(
      (conv): Sequential(
        (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))
        (1): ReLU()
        (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (4): ReLU()
        (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ReLU()
        (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (9): ReLU()
        (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (11): ReLU()
        (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (fc): Sequential(
        (0): Linear(in_features=6400, out_features=4096, bias=True)
        (1): ReLU()
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=4096, out_features=10, bias=True)
      )
    )



```python
# æœ¬å‡½æ•°å·²ä¿å­˜åœ¨d2lzh_pytorchåŒ…ä¸­æ–¹ä¾¿ä»¥åä½¿ç”¨
def load_data_fashion_mnist(batch_size, resize=None, root='/Users/chaorun/Datasets/FashionMNIST/'):
    """Download the fashion mnist dataset and then load into memory."""
    trans = []
    if resize:
        trans.append(torchvision.transforms.Resize(size=resize))
    trans.append(torchvision.transforms.ToTensor())
    
    transform = torchvision.transforms.Compose(trans)
    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)
    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)

    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2)
    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2)

    return train_iter, test_iter

#batchsize=128
batch_size = 16
# å¦‚å‡ºç°â€œout of memoryâ€çš„æŠ¥é”™ä¿¡æ¯ï¼Œå¯å‡å°batch_sizeæˆ–resize
train_iter, test_iter = load_data_fashion_mnist(batch_size,224)
for X, Y in train_iter:
    print('X =', X.shape,
        '\nY =', Y.type(torch.int32))
    break
```

    X = torch.Size([16, 1, 224, 224]) 
    Y = tensor([3, 0, 4, 4, 9, 6, 5, 7, 8, 7, 4, 3, 0, 3, 2, 4], dtype=torch.int32)



```python
lr, num_epochs = 0.001, 3
optimizer = torch.optim.Adam(net.parameters(), lr=lr)
d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)
#CPU i7-8700k  è·‘ä¸åŠ¨
```

# ä½¿ç”¨é‡å¤å…ƒç´ çš„ç½‘ç»œï¼ˆVGGï¼‰


```python
def vgg_block(num_convs, in_channels, out_channels): #å·ç§¯å±‚ä¸ªæ•°ï¼Œè¾“å…¥é€šé“æ•°ï¼Œè¾“å‡ºé€šé“æ•°
    blk = []
    for i in range(num_convs):
        if i == 0:
            blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))
        else:
            blk.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))
        blk.append(nn.ReLU())
    blk.append(nn.MaxPool2d(kernel_size=2, stride=2)) # è¿™é‡Œä¼šä½¿å®½é«˜å‡åŠ
    return nn.Sequential(*blk)
```


```python
conv_arch = ((1, 1, 64), (1, 64, 128), (2, 128, 256), (2, 256, 512), (2, 512, 512))
# ç»è¿‡5ä¸ªvgg_block, å®½é«˜ä¼šå‡åŠ5æ¬¡, å˜æˆ 224/32 = 7
fc_features = 512 * 7 * 7 # c * w * h
fc_hidden_units = 4096 # ä»»æ„
```


```python
def vgg(conv_arch, fc_features, fc_hidden_units=4096):
    net = nn.Sequential()
    # å·ç§¯å±‚éƒ¨åˆ†
    for i, (num_convs, in_channels, out_channels) in enumerate(conv_arch):
        # æ¯ç»è¿‡ä¸€ä¸ªvgg_blockéƒ½ä¼šä½¿å®½é«˜å‡åŠ
        net.add_module("vgg_block_" + str(i+1), vgg_block(num_convs, in_channels, out_channels))
    # å…¨è¿æ¥å±‚éƒ¨åˆ†
    net.add_module("fc", nn.Sequential(d2l.FlattenLayer(),
                                 nn.Linear(fc_features, fc_hidden_units),
                                 nn.ReLU(),
                                 nn.Dropout(0.5),
                                 nn.Linear(fc_hidden_units, fc_hidden_units),
                                 nn.ReLU(),
                                 nn.Dropout(0.5),
                                 nn.Linear(fc_hidden_units, 10)
                                ))
    return net
net = vgg(conv_arch, fc_features, fc_hidden_units)
X = torch.rand(1, 1, 224, 224)

# named_childrenè·å–ä¸€çº§å­æ¨¡å—åŠå…¶åå­—(named_modulesä¼šè¿”å›æ‰€æœ‰å­æ¨¡å—,åŒ…æ‹¬å­æ¨¡å—çš„å­æ¨¡å—)
for name, blk in net.named_children(): 
    X = blk(X)
    print(name, 'output shape: ', X.shape)
```

    vgg_block_1 output shape:  torch.Size([1, 64, 112, 112])
    vgg_block_2 output shape:  torch.Size([1, 128, 56, 56])
    vgg_block_3 output shape:  torch.Size([1, 256, 28, 28])
    vgg_block_4 output shape:  torch.Size([1, 512, 14, 14])
    vgg_block_5 output shape:  torch.Size([1, 512, 7, 7])
    fc output shape:  torch.Size([1, 10])



```python
ratio = 8
small_conv_arch = [(1, 1, 64//ratio), (1, 64//ratio, 128//ratio), (2, 128//ratio, 256//ratio), 
                   (2, 256//ratio, 512//ratio), (2, 512//ratio, 512//ratio)]
net = vgg(small_conv_arch, fc_features // ratio, fc_hidden_units // ratio)
print(net)
```

    Sequential(
      (vgg_block_1): Sequential(
        (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (vgg_block_2): Sequential(
        (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (vgg_block_3): Sequential(
        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU()
        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (vgg_block_4): Sequential(
        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU()
        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (vgg_block_5): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU()
        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (fc): Sequential(
        (0): FlattenLayer()
        (1): Linear(in_features=3136, out_features=512, bias=True)
        (2): ReLU()
        (3): Dropout(p=0.5, inplace=False)
        (4): Linear(in_features=512, out_features=512, bias=True)
        (5): ReLU()
        (6): Dropout(p=0.5, inplace=False)
        (7): Linear(in_features=512, out_features=10, bias=True)
      )
    )



```python
batchsize=16
#batch_size = 64
# å¦‚å‡ºç°â€œout of memoryâ€çš„æŠ¥é”™ä¿¡æ¯ï¼Œå¯å‡å°batch_sizeæˆ–resize
# train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)

lr, num_epochs = 0.001, 5
optimizer = torch.optim.Adam(net.parameters(), lr=lr)
d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)
```


```python
def nin_block(in_channels, out_channels, kernel_size, stride, padding):
    blk = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),
                        nn.ReLU(),
                        nn.Conv2d(out_channels, out_channels, kernel_size=1),
                        nn.ReLU(),
                        nn.Conv2d(out_channels, out_channels, kernel_size=1),
                        nn.ReLU())
    return blk
```


```python
# å·²ä¿å­˜åœ¨d2lzh_pytorch
class GlobalAvgPool2d(nn.Module):
    # å…¨å±€å¹³å‡æ± åŒ–å±‚å¯é€šè¿‡å°†æ± åŒ–çª—å£å½¢çŠ¶è®¾ç½®æˆè¾“å…¥çš„é«˜å’Œå®½å®ç°
    def __init__(self):
        super(GlobalAvgPool2d, self).__init__()
    def forward(self, x):
        return F.avg_pool2d(x, kernel_size=x.size()[2:])

net = nn.Sequential(
    nin_block(1, 96, kernel_size=11, stride=4, padding=0),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nin_block(96, 256, kernel_size=5, stride=1, padding=2),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nin_block(256, 384, kernel_size=3, stride=1, padding=1),
    nn.MaxPool2d(kernel_size=3, stride=2), 
    nn.Dropout(0.5),
    # æ ‡ç­¾ç±»åˆ«æ•°æ˜¯10
    nin_block(384, 10, kernel_size=3, stride=1, padding=1),
    GlobalAvgPool2d(), 
    # å°†å››ç»´çš„è¾“å‡ºè½¬æˆäºŒç»´çš„è¾“å‡ºï¼Œå…¶å½¢çŠ¶ä¸º(æ‰¹é‡å¤§å°, 10)
    d2l.FlattenLayer())
```


```python
X = torch.rand(1, 1, 224, 224)
for name, blk in net.named_children(): 
    X = blk(X)
    print(name, 'output shape: ', X.shape)
```

    0 output shape:  torch.Size([1, 96, 54, 54])
    1 output shape:  torch.Size([1, 96, 26, 26])
    2 output shape:  torch.Size([1, 256, 26, 26])
    3 output shape:  torch.Size([1, 256, 12, 12])
    4 output shape:  torch.Size([1, 384, 12, 12])
    5 output shape:  torch.Size([1, 384, 5, 5])
    6 output shape:  torch.Size([1, 384, 5, 5])
    7 output shape:  torch.Size([1, 10, 5, 5])
    8 output shape:  torch.Size([1, 10, 1, 1])
    9 output shape:  torch.Size([1, 10])



```python
batch_size = 128
# å¦‚å‡ºç°â€œout of memoryâ€çš„æŠ¥é”™ä¿¡æ¯ï¼Œå¯å‡å°batch_sizeæˆ–resize
#train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)

lr, num_epochs = 0.002, 5
optimizer = torch.optim.Adam(net.parameters(), lr=lr)
d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)
```


```python

```

# GoogLeNet


```python
class Inception(nn.Module):
    # c1 - c4ä¸ºæ¯æ¡çº¿è·¯é‡Œçš„å±‚çš„è¾“å‡ºé€šé“æ•°
    def __init__(self, in_c, c1, c2, c3, c4):
        super(Inception, self).__init__()
        # çº¿è·¯1ï¼Œå•1 x 1å·ç§¯å±‚
        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)
        # çº¿è·¯2ï¼Œ1 x 1å·ç§¯å±‚åæ¥3 x 3å·ç§¯å±‚
        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)
        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)
        # çº¿è·¯3ï¼Œ1 x 1å·ç§¯å±‚åæ¥5 x 5å·ç§¯å±‚
        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)
        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)
        # çº¿è·¯4ï¼Œ3 x 3æœ€å¤§æ± åŒ–å±‚åæ¥1 x 1å·ç§¯å±‚
        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)
        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1)

    def forward(self, x):
        p1 = F.relu(self.p1_1(x))
        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))
        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))
        p4 = F.relu(self.p4_2(self.p4_1(x)))
        return torch.cat((p1, p2, p3, p4), dim=1)  # åœ¨é€šé“ç»´ä¸Šè¿ç»“è¾“å‡º
```


```python
b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),
                   nn.ReLU(),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))

b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),
                   nn.Conv2d(64, 192, kernel_size=3, padding=1),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))

b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),
                   Inception(256, 128, (128, 192), (32, 96), 64),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))

b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),
                   Inception(512, 160, (112, 224), (24, 64), 64),
                   Inception(512, 128, (128, 256), (24, 64), 64),
                   Inception(512, 112, (144, 288), (32, 64), 64),
                   Inception(528, 256, (160, 320), (32, 128), 128),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))

b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),
                   Inception(832, 384, (192, 384), (48, 128), 128),
                   d2l.GlobalAvgPool2d())

net = nn.Sequential(b1, b2, b3, b4, b5, 
                    d2l.FlattenLayer(), nn.Linear(1024, 10))

net = nn.Sequential(b1, b2, b3, b4, b5, d2l.FlattenLayer(), nn.Linear(1024, 10))

X = torch.rand(1, 1, 96, 96)

for blk in net.children(): 
    X = blk(X)
    print('output shape: ', X.shape)

#batchsize=128
batch_size = 16
# å¦‚å‡ºç°â€œout of memoryâ€çš„æŠ¥é”™ä¿¡æ¯ï¼Œå¯å‡å°batch_sizeæˆ–resize
#train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)

lr, num_epochs = 0.001, 5
optimizer = torch.optim.Adam(net.parameters(), lr=lr)
#d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)
```

    output shape:  torch.Size([1, 64, 24, 24])
    output shape:  torch.Size([1, 192, 12, 12])
    output shape:  torch.Size([1, 480, 6, 6])
    output shape:  torch.Size([1, 832, 3, 3])
    output shape:  torch.Size([1, 1024, 1, 1])
    output shape:  torch.Size([1, 1024])
    output shape:  torch.Size([1, 10])



```python

```
